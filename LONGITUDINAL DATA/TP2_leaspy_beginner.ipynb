{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNIUGkW-3Qrv"
      },
      "source": [
        "# First steps with Leaspy\n",
        "\n",
        "Welcome for the second practical session of the day!\n",
        "\n",
        "### Objectives :\n",
        "- Learn to use Leaspy methods\n",
        "\n",
        "\n",
        "# The set-up\n",
        "\n",
        "As before, if you have followed the [installation details](https://gitlab.com/icm-institute/aramislab/disease-course-mapping-solutions) carefully, you should\n",
        "\n",
        "- be running this notebook in the `leaspy_tutorial` virtual environment\n",
        "- having all the needed packages already installed\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 1 üí¨</span> __Run the following command lines__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIongcp_3Qr0"
      },
      "outputs": [],
      "source": [
        "!pip install leaspy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2_-e_4j3Qr1"
      },
      "outputs": [],
      "source": [
        "!git clone https://gitlab.com/icm-institute/aramislab/disease-course-mapping-solutions.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6qIJ6Pe3Qr1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "pd.options.display.float_format = '{:.4g}'.format\n",
        "\n",
        "# import main classes from Leaspy package\n",
        "from leaspy import Leaspy, Data, AlgorithmSettings, IndividualParameters, __watermark__\n",
        "from leaspy.io.logs.visualization.plotting import Plotting\n",
        "\n",
        "data_path = lambda *p: os.path.join('./disease-course-mapping-solutions/challenges/TP2_leaspy_beginner/data', *p)\n",
        "\n",
        "# Watermark trace with all packages versions\n",
        "__watermark__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d5jRfNK3Qr2"
      },
      "source": [
        "# Part I: Data\n",
        "\n",
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> Data that can be used as a leaspy input should have the following format.\n",
        "\n",
        "#### This result in multiple rows per subject. The input format **_MUST_** follow the following rules:\n",
        "- A column named `ID`: corresponds to the subject indices\n",
        "- A columns named `TIME`: corresponds to the subject's age at the corresponding visit\n",
        "- One column per feature\n",
        "- Each row is a visit, therefore the concatenation of the subject ID, the patient age at which the corresponding visit occurred, and then the feature values\n",
        "\n",
        "#### Concerning the features' values, as we are using a logistic model, they **_MUST_**:\n",
        "- Be between 0 and 1\n",
        "- In average increase with time for each subject (normal states correspond to values near 0 and pathological states to values near 1)\n",
        "\n",
        "Moreover, to calibrate the progression model, we highly recommend to keep subjects that have been seen at least two times. You probably noticed that there are NaN: do not worry, Leaspy can handle them ;)\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 2 üí¨</span> __Run the following lines to load the data.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdweqeZz3Qr4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(data_path('simulated_data-corrected.csv'))\n",
        "df = df.set_index([\"ID\",\"TIME\"], verify_integrity=True).sort_index()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IBfxJAL3Qr4"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 3 üí¨</span> __Does the data set seem to have the good format?__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "challenge"
        ],
        "id": "tIpNzF903Qr5"
      },
      "source": [
        "Your answer: ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyMOVDwA3Qr6"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 4 üí¨</span> __How many patients are there in the dataset?__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "challenge"
        ],
        "id": "PnxwuCTC3Qr-"
      },
      "outputs": [],
      "source": [
        "# To complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ogBH4cr3Qr-"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 5 üí¨</span> __Create a training test that contains the first 160 patients and a testing set the rest. Each set will only contain the following features:__\n",
        "- __MDS1_total__\n",
        "- __MDS2_total__\n",
        "- __MDS3_off_total__\n",
        "\n",
        "Help : Be careful, one patient is not one line ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "challenge"
        ],
        "id": "h79RatIh3Qr_"
      },
      "outputs": [],
      "source": [
        "# To complete\n",
        "\n",
        "df_train = ######################\n",
        "df_test = ######################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZFT8oGi3QsA"
      },
      "source": [
        "### Leaspy's `Data` container\n",
        "\n",
        "\n",
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> _Leaspy_ comes with its own data containers. The one used in a daily basis is `Data`. You can load your data from a csv with it `Data.from_csv_file` or from a DataFrame `Data.from_dataframe`.\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 6 üí¨</span> __Run the following lines to convert DataFrame into Data object.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZnSwJUo3QsB"
      },
      "outputs": [],
      "source": [
        "data_train = Data.from_dataframe(df_train)\n",
        "data_test = Data.from_dataframe(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Znmigt63QsK"
      },
      "source": [
        "# Part II : Instantiate a `Leaspy` object\n",
        "\n",
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> Before creating a leaspy object, you need to choose the type of progression shape you want to give to your data. The available models are the following:\n",
        "- linear\n",
        "- logistic\n",
        "\n",
        "with the possibility to enforce a _parallelism_ between the features. **_Parallelism_** imposes that all the features have the same average pace of progression.\n",
        "\n",
        "Once that is done, you just have to call `Leaspy('model_name')`. The dedicated names are  :\n",
        "- `univariate_linear`\n",
        "- `linear`\n",
        "- `univariate_logistic`\n",
        "- `logistic`\n",
        "- `logistic_parallel`\n",
        "- `lme_model`\n",
        "- `constant_model`\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 7 üí¨</span> __We choose a logistic model. Run the following line to instantiate the leaspy object.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhovOThv3QsL"
      },
      "outputs": [],
      "source": [
        "leaspy = Leaspy(\"logistic\",\n",
        "                source_dimension=2,             # number of dimensions for non-temporal inter-subject variability\n",
        "                noise_model='gaussian_diagonal' # estimate the residual noise scaling per feature\n",
        "         )\n",
        "leaspy_plotting = Plotting(leaspy.model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-v6lmOk3QsM"
      },
      "source": [
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> `Leaspy` object contains all the main methods provided by the software. With this object, you can:\n",
        "- **calibrate** a model\n",
        "- **personalize** a model to individual data (basically you infer the random effects with a gradient descent)\n",
        "- **estimate** the features values of subjects at given ages based on your calibrated model and their individual parameters\n",
        "- **simulate** synthetic subjects base on your calibrated model, a collection of individual parameters and data\n",
        "- **load** and **save** a model\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 8 üí¨</span> __Check it out by running the following line__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh3glrNS3QsM"
      },
      "outputs": [],
      "source": [
        "? Leaspy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zClAS4lD3QsN"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 9 üí¨</span> __This `Leaspy` object comes with an handy attribute for visualization. Let's have a look on the data that will be used to calibrate our model__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUMSSOmY3QsN"
      },
      "outputs": [],
      "source": [
        "ax = leaspy_plotting.patient_observations(data_train, alpha=.7, figsize=(14, 6))\n",
        "ax.set_ylim(0,.8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRKhl0Li3QsO"
      },
      "source": [
        "Well... not so engaging, right? Let's see what Leaspy can do for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRc1V2NZ3QsO"
      },
      "source": [
        "# Part III : Choose your algorithms\n",
        "\n",
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> Once you chose your model, you need to choose an algorithm to calibrate it.\n",
        "\n",
        "To run any algorithm, you need to specify the settings of the related algorithm thanks to the `AlgorithmSettings` object. To ease Leaspy's usage for new users, we specified default values for each algorithm. Therefore, the name of the algorithm used is enough to run it. The one you need to fit your progression model is `mcmc_saem`, which stands for <a href=\"https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo\" target=\"_blank\">Markov chain Monte Carlo</a> - Stochastic Approximation of <a href=\"https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm\" target=\"_blank\">Expectation Maximization</a>.\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 10 üí¨</span> __Run the following line to instantiate a `AlgorithmSettings` object.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljUehylL3QsO"
      },
      "outputs": [],
      "source": [
        "algo_settings = AlgorithmSettings('mcmc_saem',\n",
        "                                  n_iter=3000,           # n_iter defines the number of iterations\n",
        "                                  seed=0)                # to make the calibration deterministic for reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRmF3fW83QsP"
      },
      "source": [
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> You can specify many more settings that are left by default for now. You can also save and load an `AlgorithmSettings` object in a json file.\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 11 üí¨</span> __Run the following line to get more informations.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_nQk_CO3QsP"
      },
      "outputs": [],
      "source": [
        "? AlgorithmSettings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjApth713QsQ"
      },
      "source": [
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> It is often useful, even if it is optional to store the different logs of the model during the iterations. You can use the following method with the path of the folder where the logs will be stored.\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 12 üí¨</span> __Run the following lines.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS1PimkQ3QsQ"
      },
      "outputs": [],
      "source": [
        "algo_settings.set_logs(\n",
        "    path='logs',          # Creates a logs file ; if existing, ask if rewrite it\n",
        "    plot_periodicity=500,  # Saves the values to display in pdf every 50 iterations\n",
        "    save_periodicity=10,  # Saves the values in csv files every 10 iterations\n",
        "    console_print_periodicity=None,  # If = N, it display logs in the console/terminal every N iterations\n",
        "    overwrite_logs_folder=True       # Default behaviour raise an error if the folder already exists.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCBOM_NK3QsQ"
      },
      "source": [
        "# Part IV : Fit your model\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 13 üí¨</span> __Run the following lines to fit the model.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1lgZ-W13QsR"
      },
      "outputs": [],
      "source": [
        "leaspy.fit(data_train, settings=algo_settings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QPZBSaK3QsR"
      },
      "source": [
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> This might take several minutes, so let's discuss about the _keyword argument_ `source_dimension`. This parameters depend on the number of variable you want the model to learn: it can go from 1 to the number of variables. If it is not set by the user the default value is $\\sqrt{N_{features}}$ as it has been shown empirically to give good results. You will learn more about the mathematical formulation of the model below (part V)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs9EISFj3QsS"
      },
      "source": [
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> Before assuming that the model is estimated, you have to check that the convergence went well. For that, you can look the at the convergence during the iterations. To do so, you can explore the `logs` folder (in the same folder than this jupyter notebook) that shows the model convergence during the iterations. The first thing to look at is probably the `plots/convergence_1.pdf` and `plots/convergence_2.pdf` files : a run has had enough iterations to converge if the last 20 or even 30% of the iterations were stable for all the parameters. If not, you should provably re-run it with more iterations.\n",
        "\n",
        "We first need to import a library to display the PDF, so run the following cells :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "challenge"
        ],
        "id": "TjXBO4fU3QsS"
      },
      "outputs": [],
      "source": [
        "!sudo apt install poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "challenge"
        ],
        "id": "oIaDaQP33QsU"
      },
      "outputs": [],
      "source": [
        "!pip install pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "challenge"
        ],
        "id": "8otrU2s_3QsU"
      },
      "outputs": [],
      "source": [
        "from pdf2image import convert_from_path\n",
        "\n",
        "images = convert_from_path('./logs/plots/convergence_1.pdf')\n",
        "images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk79l1vF3QsV"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 14 üí¨</span> __Check out the parameters of the model that are stored here__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "323M9c033QsV"
      },
      "outputs": [],
      "source": [
        "leaspy.model.parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH5X2IgP3QsV"
      },
      "source": [
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span>  Parameters are probably not straightforward for now. The most important one is probably `noise_std`. It corresponds to the standard deviation of the Gaussian errors (one per feature). The smallest, the better - up to the lower bound which is the intrinsic noise in the data. Note that usually, cognitive measurements have an intrinsic error (computed on test-retest exams) between 5% and 10%.\n",
        "\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 15 üí¨</span> __Let's display `noise_std`__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPpvPuLQ3QsV"
      },
      "outputs": [],
      "source": [
        "noise = leaspy.model.parameters['noise_std']\n",
        "features = leaspy.model.features\n",
        "\n",
        "print('Standard deviation of the residual noise for the feature:')\n",
        "for n, f in zip(noise, features):\n",
        "    print(f'- {f}: {n*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdv72cey3QsW"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 16 üí¨</span> __Save the model with the command below__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky3sAllm3QsW"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"outputs/\"):\n",
        "    os.makedirs(\"outputs/\")\n",
        "\n",
        "leaspy.save(\"outputs/model_parameters.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1plx3gH3QsX"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 17 üí¨</span> __Load the model with the command below__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGGPzs4W3QsX"
      },
      "outputs": [],
      "source": [
        "leaspy = Leaspy.load('outputs/model_parameters.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHQvC3nW3QsX"
      },
      "source": [
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> Now that we have sufficient evidence that the model has converged, let's output what the average progression looks like!\n",
        "\n",
        "First, let's detail a bit what we are going to represent. We are going to display a trajectory: it corresponds to the temporal progression of the biomarkers. There is not only one trajectory for a cohort, as each subject has his or her own specific trajectory, meaning his or her disease progression. Each of these individual trajectories rely on individual parameters that are subject-specific. We will see those individual parameters a bit later, do not worry. For now, let's stick to the _average_ trajectory.\n",
        "\n",
        "So what does the average trajectory corresponds to? The average trajectory correspond to a _virtual patient_ whose individual parameters are the average individual parameters. And these averages are already estimated during the calibration.\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 18 üí¨</span> __Let's plot the average trajectory__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zInHfuZg3QsX"
      },
      "outputs": [],
      "source": [
        "ax = leaspy_plotting.average_trajectory(alpha=1, figsize=(14,6), n_std_left=2, n_std_right=8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPSxkZwc3QsY"
      },
      "source": [
        "# Part V : Personalize the model to individual data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5GaXkGy3QsY"
      },
      "source": [
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> The personalization procedure allows to estimate the individual parameters that allows to modify the average progression to individual observations. The variations from the average trajectory to the individual one are encoded within three individual parameters :\n",
        "- $\\alpha_i = \\exp(\\xi_i)$ : the acceleration factor, that modulates the speed of progression : $\\alpha_i > 1$ means faster, $\\alpha_i < 1$ means slower than the average progression\n",
        "- $\\tau_i$ : the time shift which delays the progression in a given number of years. It has to be compared to  `tau_mean` $ = \\bar{\\tau} $  which is in the model parameters above. In fact, $ \\tau_i \\sim \\mathcal{N}( \\bar{\\tau}, \\sigma_{\\tau}^2)$ , so $\\tau_i > \\bar{\\tau}$ means that the patient has a disease that starts later than average, while $\\tau_i < \\bar{\\tau}$ means that the patient has a disease that starts earlier than average\n",
        "- $w_i = (w_1, ..., w_N)$ ($N$ being the number of features) : the space-shift which might, for a given individual, change the ordering of the conversion of the different features, compared to the mean trajectory.\n",
        "\n",
        "In a nutshell, the $k$-th feature at the $j$-th visit of subject $i$, which occurs at time $t_{ij}$ writes:\n",
        "\n",
        "$$y_{ijk} = f_\\theta ( w_{ik}+ \\exp(\\xi_i) * (t_{ij} - \\tau_i) ) + \\epsilon_{ijk}$$\n",
        "\n",
        "With:\n",
        "- $\\theta$ being the population parameters, inferred during calibration of the model,\n",
        "- $f_\\nu$ a parametric family of trajectories depending of model type,\n",
        "- $\\epsilon_{ijk}$ an independent normally distributed error term.\n",
        "\n",
        "This writing is not exactly correct but helps understand the role of each individual parameters.\n",
        "\n",
        "**[ Advanced ]** Remember the `sources`, or the `source_dimension`? Well, $w_i$ is not estimated directly, but rather thanks to a Independent Component Analysis, such that $w_i = A s_i$ where $s_i$ is of dimension $N_s$ = `source_dimension`. See associated papers for further details.\n",
        "\n",
        "Now, let's estimate these individual parameters. The procedure relies on the `scipy_minimize` algorithm (gradient descent) that you have to define (or to load from an appropriate json file) :\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 19 üí¨</span> __First set the parameters__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLXJsA8K3QsZ"
      },
      "outputs": [],
      "source": [
        "settings_personalization = AlgorithmSettings('scipy_minimize', seed=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaqduIiq3Qsa"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 20a üí¨</span> __Then use the second most important function of leaspy : `leaspy.personalize`. It estimates the individual parameters for the data you provide:__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "SSMbRIcO3Qsa"
      },
      "outputs": [],
      "source": [
        "?leaspy.personalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrDT35vW3Qsb"
      },
      "outputs": [],
      "source": [
        "ip = leaspy.personalize(data_test, settings_personalization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNbZiXgS3Qsc"
      },
      "source": [
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> Note here that you can personalize your model on patients that have only one visit! And you don't have to use the same `data` as previously. It is especially useful, and important, in order to validate your model!\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 20b üí¨</span> __Once the personalization is done, check the different functions that the `IndividualParameters` provides (you can save and load them, transform them to dataframes, etc) :__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsTgjooZ3Qsc"
      },
      "outputs": [],
      "source": [
        "?ip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9NrQULV3Qsc"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 21 üí¨</span> __Plot the test data, but with reparametrized ages instead of real ages__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FU30KTm3Qsc"
      },
      "outputs": [],
      "source": [
        "# Plot the test data with individually reparametrized ages\n",
        "ax = leaspy_plotting.patient_observations_reparametrized(data_test, ip,\n",
        "                                                         alpha=.7, linestyle='-',\n",
        "                                                         #patients_idx=list(data_test.individuals.keys())[:4],\n",
        "                                                         figsize=(14, 6))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pxzz4wH3Qsd"
      },
      "source": [
        "Remember the raw plotting of values during question 9? Better, no?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyqMXUOw3Qsd"
      },
      "outputs": [],
      "source": [
        "# Plot the test data with individually with true ages\n",
        "ax = leaspy_plotting.patient_observations(data_test,\n",
        "                                          alpha=.7, linestyle='-',\n",
        "                                          #patients_idx=list(data_test.individuals.keys())[:4],\n",
        "                                          figsize=(14, 6))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AFziwWH3Qsd"
      },
      "source": [
        "Now, let's see what you can do with the individual parameters.\n",
        "\n",
        "# Part VI : Impute missing values & predict individual trajectories\n",
        "\n",
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> Together with the population parameters, the individual parameters entirely defines the individual trajectory, and thus, the biomarker values at any time. So you can reconstruct the individual biomarkers at different ages.\n",
        "\n",
        "You can reconstruct your observations at seen ages, i.e. at visits that have been used to personalize the model. There are two reasons you might want to do that:\n",
        "- see how well the model fitted individual data\n",
        "- impute missing values: as Leaspy handles missing values, it can then reconstruct them (note that this reconstruction will be noiseless)\n",
        "\n",
        "\n",
        "The third very important function - after `leaspy.fit` and `leaspy.personalize` - is `leaspy.estimate`. Given some individual parameters and timepoints, the function estimates the values of the biomarkers at the given timepoints which derive from the individual trajectory encoded thanks to the individual parameters.\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 22 üí¨</span> __Check out the documentation__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCzGYxDI3Qse"
      },
      "outputs": [],
      "source": [
        "?leaspy.estimate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9W2Yp5B3Qse"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 23 üí¨</span> __Before running `leaspy.estimate`, let's first retrieve the observations of subject 'GS-187' in the initial dataset. Get also his/her individual parameters as shown here:__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMa4vLuH3Qse"
      },
      "outputs": [],
      "source": [
        "observations = df_test.loc['GS-187']\n",
        "print(f'Seen ages: {observations.index.values}')\n",
        "print(\"Individual Parameters : \", ip['GS-187'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiA5UAG-3Qsf"
      },
      "source": [
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> The `estimate` first argument is a dictionary, so that you can estimate the trajectory of multiple individuals simultaneously (as long as the individual parameters of all your queried patients are in `ip`.\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 24 üí¨</span> __Now, let's estimate the trajectory for this patient.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVO9WJTC3Qsf"
      },
      "outputs": [],
      "source": [
        "timepoints = np.linspace(60, 100, 100)\n",
        "reconstruction = leaspy.estimate({'GS-187': timepoints}, ip)\n",
        "\n",
        "def plot_trajectory(timepoints, reconstruction, observations=None):\n",
        "\n",
        "    if observations is not None:\n",
        "        ages = observations.index.values\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.ylim(0, .75)\n",
        "    plt.ylabel('Biomarker normalized value')\n",
        "    plt.xlim(60, 100)\n",
        "    plt.xlabel('Patient age')\n",
        "    colors = ['#003f5c', '#7a5195', '#ef5675', '#ffa600']\n",
        "\n",
        "    for c, name, val in zip(colors, leaspy.model.features, reconstruction.T):\n",
        "        plt.plot(timepoints, val, label=name, c=c, linewidth=3)\n",
        "        if observations is not None:\n",
        "            plt.plot(ages, observations[name], c=c, marker='o', markersize=12)\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_trajectory(timepoints, reconstruction['GS-187'], observations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTZjlJ6S3Qsf"
      },
      "outputs": [],
      "source": [
        "# Or with plotting object\n",
        "ax = leaspy_plotting.patient_trajectories(data_test, ip,\n",
        "                                          patients_idx=['GS-187','GS-180'],\n",
        "                                          labels=['MDS1','MDS2', 'MDS3 (off)'],\n",
        "                                          #reparametrized_ages=True, # check sources effect\n",
        "\n",
        "                                          # plot kwargs\n",
        "                                          #color=['#003f5c', '#7a5195', '#ef5675', '#ffa600'],\n",
        "                                          alpha=1, linestyle='-', linewidth=2,\n",
        "                                          #marker=None,\n",
        "                                          markersize=8, obs_alpha=.5, #obs_ls=':',\n",
        "                                          figsize=(16, 6),\n",
        "                                          factor_past=.5,\n",
        "                                          factor_future=5, # future extrapolation\n",
        "                                          )\n",
        "#ax.set_ylim(0, .75)\n",
        "ax.set_xlim(45, 120)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmibDKUx3Qsg"
      },
      "outputs": [],
      "source": [
        "# Grasp source effects\n",
        "ax = leaspy_plotting.patient_trajectories(data_test, ip,\n",
        "                                          patients_idx='all',\n",
        "                                          labels=['MDS1','MDS2', 'MDS3 (off)'],\n",
        "                                          reparametrized_ages=True, # check sources effect\n",
        "\n",
        "                                          # plot kwargs\n",
        "                                          alpha=1, linestyle='-', linewidth=1,\n",
        "                                          marker=None,\n",
        "                                          figsize=(16, 6),\n",
        "                                          factor_past=0,\n",
        "                                          factor_future=0, # no extrapolation (future) nor past\n",
        "                                          )\n",
        "#ax.set_ylim(0, .75)\n",
        "#ax.set_xlim(45, 120)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjv07-tl3Qsg"
      },
      "source": [
        "# Part VII : Leaspy application - Cofactor analysis\n",
        "\n",
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> Besides prediction, the individual parameters are interesting in the sense that they provide meaningful and interesting insights about the disease progression. For that reason, these individual parameters can be correlated to other cofactors. Let's consider that you have a covariate _Cofactor 1_ that encodes a genetic status: 1 if a specific mutation is present, 0 otherwise.\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 25 üí¨</span> __Now, let's see if this mutation has an effect on the disease progression:__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjJHDUet3Qsg"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# ‚Äî‚Äî Convert individual parameters to dataframe\n",
        "df_ip = ip.to_dataframe()\n",
        "\n",
        "# ‚Äî‚Äî Join the cofactors to individual parameters\n",
        "cofactor = pd.read_csv(data_path('cof_leaspy1.csv'), index_col=['ID'])\n",
        "df_ip = df_ip.join(cofactor.replace({'MUTATION':{0: 'Non-carrier', 1: 'Carrier'}}))\n",
        "\n",
        "_, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# ‚Äî‚Äî Plot the time shifts in carriers and non-carriers\n",
        "ax[0].set_title('Time shift histogram')\n",
        "sns.histplot(data=df_ip, x='tau', hue='MUTATION', bins=15, ax=ax[0], stat='count', common_norm=False, kde=True)\n",
        "\n",
        "# ‚Äî‚Äî Plot the acceleration factor in carriers and non-carriers\n",
        "ax[1].set_title('Log-Acceleration factor histogram')\n",
        "sns.histplot(data=df_ip, x='xi', hue='MUTATION', bins=15, ax=ax[1], stat='count', common_norm=False, kde=True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# __ Joint density (tau, xi) __\n",
        "g = sns.jointplot(data=df_ip, x=\"tau\", y=\"xi\", hue=\"MUTATION\", height=6)\n",
        "g.plot_joint(sns.kdeplot, zorder=0, levels=8, bw_adjust=1.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0mgavE_3Qsh"
      },
      "source": [
        " <span style='color: #a13203; font-weight: 600;'>üí¨ Question 26 üí¨</span> __Now, check your hypothesis with statistical tests__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT1m7THf3Qsh"
      },
      "outputs": [],
      "source": [
        "# Shortcuts of df_ip for 2 sub-populations\n",
        "carriers = df_ip[df_ip['MUTATION'] == 'Carrier']\n",
        "non_carriers = df_ip[df_ip['MUTATION'] == 'Non-carrier']\n",
        "# ‚Äî‚Äî Student t-test (under the assumption of a gaussian distribution only)\n",
        "print(stats.ttest_ind(carriers['tau'], non_carriers['tau']))\n",
        "print(stats.ttest_ind(carriers['xi'], non_carriers['xi']))\n",
        "\n",
        "# ‚Äî‚Äî Mann-Withney t-test\n",
        "print(stats.mannwhitneyu(carriers['tau'], non_carriers['tau']))\n",
        "print(stats.mannwhitneyu(carriers['xi'], non_carriers['xi']))\n",
        "\n",
        "# Do you think to other approaches for testing your hypothesis?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75pSOizq3Qsh"
      },
      "source": [
        "# Part VIII : Data Simulation\n",
        "\n",
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> Now that you are able to predict the evolution of a patient and use it to analyse cofactors, you might want to simulate a new one thanks to the information that you have learned. To do so you can use the last method of leaspy that we will study : `simulate`.\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 27 üí¨</span> __Have a look to the function__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WExQG_XF3Qsi"
      },
      "outputs": [],
      "source": [
        "?leaspy.simulate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhJ89DWd3Qsi"
      },
      "source": [
        "<span style='color: #015e75; font-weight: 600;'>‚ÑπÔ∏è Information ‚ÑπÔ∏è</span> To use the function we will first extract the individual parameters using personalize with `mode_real` option. The simulate function learns the joined distribution of the individual parameters and baseline age of the subjects\n",
        "present in ``individual_parameters`` and ``data`` respectively to sample new patients from this joined distribution.\n",
        "\n",
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 28 üí¨</span> __Define the settings for the personalization and get the individual parameters__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5VtaFhf3Qsj"
      },
      "outputs": [],
      "source": [
        "settings_ip_simulate = AlgorithmSettings('mode_real', seed=0)\n",
        "individual_params = leaspy.personalize(data_test, settings_ip_simulate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOiuof-33Qsj"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 29 üí¨</span> __Define your algorithm for the simulation and simulate individuals from previously obtained individual parameters and dataset__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0euViC6E3Qsk"
      },
      "outputs": [],
      "source": [
        "# You can tweak many parameters for the simulation, cf. the full reference: https://leaspy.readthedocs.io/en/latest/generated/leaspy.algo.simulate.simulate.SimulationAlgorithm.html\n",
        "settings_simulate = AlgorithmSettings('simulation', seed=0)\n",
        "simulated_data = leaspy.simulate(individual_params, data_test, settings_simulate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "budaYH3o3Qsk"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 30 üí¨</span> __Access to the individual parameters of one individual that you have created__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "he24Jk0t3Qsk"
      },
      "outputs": [],
      "source": [
        "print(simulated_data.get_patient_individual_parameters(\"Generated_subject_001\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4gyIuTX3Qsm"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 31 üí¨</span> __Plot the joint distribution of individual parameters (tau, xi) for simulated individuals that you have created__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8U6LFho3Qsm"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe with individual parameters from both real & simulated individuals\n",
        "df_ip_both = pd.concat({\n",
        "    'estimated': individual_params.to_dataframe(),\n",
        "    'simulated': simulated_data.get_dataframe_individual_parameters()\n",
        "}, names=['Origin'])\n",
        "\n",
        "g = sns.jointplot(data=df_ip_both, x='tau', y='xi', hue='Origin', height=8,\n",
        "                  marginal_kws=dict(common_norm=False))\n",
        "g.plot_joint(sns.kdeplot, zorder=0, levels=8, bw_adjust=2.);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gUW9G7o3Qsm"
      },
      "source": [
        "<span style='color: #a13203; font-weight: 600;'>üí¨ Question 32 üí¨</span> __Plot some simulated individual trajectories__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-Ka4UXR3Qsn"
      },
      "outputs": [],
      "source": [
        "# Or with plotting object\n",
        "ax = leaspy_plotting.patient_trajectories(simulated_data.data,\n",
        "                                          IndividualParameters().from_dataframe(simulated_data.get_dataframe_individual_parameters()),\n",
        "                                          patients_idx=[f'Generated_subject_{i:03}' for i in [1,2,7,42]],\n",
        "                                          labels=['MDS1','MDS2', 'MDS3 (off)'],\n",
        "                                          #reparametrized_ages=True, # check sources effect\n",
        "\n",
        "                                          # plot kwargs\n",
        "                                          #color=['#003f5c', '#7a5195', '#ef5675', '#ffa600'],\n",
        "                                          alpha=1, linestyle='-', linewidth=2,\n",
        "                                          #marker=None,\n",
        "                                          markersize=8, obs_alpha=.5, #obs_ls=':',\n",
        "                                          figsize=(16, 6),\n",
        "                                          factor_past=.5,\n",
        "                                          factor_future=5, # future extrapolation\n",
        "                                          )\n",
        "ax.set_title(\"Simulated observations and individual trajectories\")\n",
        "#ax.set_ylim(0, .75)\n",
        "ax.set_xlim(45, 120)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AG5PwfK3Qsn"
      },
      "source": [
        "# Congratulations this is the end !!!!!\n",
        "\n",
        "You can now have a break ;)"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "formats": "ipynb,md",
      "text_representation": {
        "extension": ".md",
        "format_name": "markdown",
        "format_version": "1.3",
        "jupytext_version": "1.13.5"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "TP2_leaspy_beginner.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yCBOM_NK3QsQ",
        "fPSxkZwc3QsY",
        "3AFziwWH3Qsd",
        "sjv07-tl3Qsg",
        "75pSOizq3Qsh",
        "1AG5PwfK3Qsn"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}